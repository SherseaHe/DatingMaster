# ğŸ¤ å‰ç«¯å®æ—¶å½•éŸ³é›†æˆæŒ‡å—

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

ä¸ºå‰ç«¯åŒäº‹æä¾›çš„å®æ—¶å½•éŸ³è¯­éŸ³è¯†åˆ«+AIå¯¹è¯è§£å†³æ–¹æ¡ˆã€‚æŒ‰ä¸‹å½•éŸ³æŒ‰é’®å¼€å§‹å½•éŸ³ï¼Œæ¾å¼€è‡ªåŠ¨è°ƒç”¨è®¯é£æ¨¡å‹è½¬æ–‡å­—ï¼Œç„¶åäº¤ç»™Kimiå¤„ç†ç”Ÿæˆå›å¤ã€‚

## ğŸ”Œ WebSocketè¿æ¥

### **è¿æ¥åœ°å€**
```javascript
const wsUrl = `ws://localhost:3000/api/realtime-voice`;
// ç”Ÿäº§ç¯å¢ƒ: wss://your-domain.com/api/realtime-voice
```

### **è¿æ¥ç¤ºä¾‹**
```javascript
const ws = new WebSocket('ws://localhost:3000/api/realtime-voice');

ws.onopen = () => {
    console.log('å®æ—¶è¯­éŸ³è¿æ¥å·²å»ºç«‹');
};

ws.onmessage = (event) => {
    const message = JSON.parse(event.data);
    handleMessage(message);
};
```

## ğŸ™ï¸ å½•éŸ³æµç¨‹

### **1. å¼€å§‹å½•éŸ³**
```javascript
// å‘é€å¼€å§‹å½•éŸ³æ¶ˆæ¯
ws.send(JSON.stringify({
    type: 'start_recording',
    language: 'zh_cn',  // æˆ– 'en_us'
    model: 'moonshot-v1-8k'  // Kimiæ¨¡å‹
}));

// å¼€å§‹åª’ä½“å½•éŸ³
mediaRecorder.start(100); // æ¯100mså‘é€ä¸€æ¬¡æ•°æ®
```

### **2. å‘é€éŸ³é¢‘æ•°æ®**
```javascript
mediaRecorder.ondataavailable = (event) => {
    if (event.data.size > 0) {
        // ç›´æ¥å‘é€éŸ³é¢‘Blobæ•°æ®
        ws.send(event.data);
    }
};
```

### **3. åœæ­¢å½•éŸ³**
```javascript
// åœæ­¢åª’ä½“å½•éŸ³
mediaRecorder.stop();

// å‘é€åœæ­¢å½•éŸ³æ¶ˆæ¯
ws.send(JSON.stringify({
    type: 'stop_recording'
}));
```

## ğŸ“¨ æ¶ˆæ¯åè®®

### **å‘é€æ¶ˆæ¯æ ¼å¼**

#### **å¼€å§‹å½•éŸ³**
```json
{
    "type": "start_recording",
    "language": "zh_cn",
    "model": "moonshot-v1-8k",
    "streamMode": false
}
```

#### **åˆ‡æ¢å½•éŸ³çŠ¶æ€ï¼ˆå®æ—¶æ¨¡å¼ï¼‰**
```json
{
    "type": "toggle_recording",
    "language": "zh_cn",
    "model": "moonshot-v1-8k",
    "streamMode": true
}
```

#### **åœæ­¢å½•éŸ³**
```json
{
    "type": "stop_recording"
}
```

#### **æ¸…é™¤å†å²**
```json
{
    "type": "clear_history"
}
```

#### **æ›´æ–°é…ç½®**
```json
{
    "type": "config",
    "language": "zh_cn",
    "model": "moonshot-v1-32k"
}
```

### **æ¥æ”¶æ¶ˆæ¯æ ¼å¼**

#### **è¿æ¥æˆåŠŸ**
```json
{
    "type": "connected",
    "sessionId": "voice_1234567890_abc123",
    "message": "å®æ—¶è¯­éŸ³è¯†åˆ«è¿æ¥å·²å»ºç«‹",
    "timestamp": "2024-01-01T12:00:00.000Z"
}
```

#### **å½•éŸ³å¼€å§‹**
```json
{
    "type": "recording_started",
    "message": "å¼€å§‹å½•éŸ³",
    "config": {
        "language": "zh_cn",
        "model": "moonshot-v1-8k"
    }
}
```

#### **å½•éŸ³è¿›åº¦**
```json
{
    "type": "recording_progress",
    "audioSize": 12345,
    "duration": 2500
}
```

#### **å¤„ç†çŠ¶æ€**
```json
{
    "type": "processing",
    "step": "transcription",
    "message": "æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«..."
}
```

#### **è¯†åˆ«ç»“æœ**
```json
{
    "type": "transcription_result",
    "data": {
        "text": "æ‚¨è¯´çš„å†…å®¹",
        "confidence": 0.95,
        "language": "zh_cn",
        "duration": 2500
    }
}
```

#### **å®æ—¶è¯†åˆ«ç»“æœ**
```json
{
    "type": "stream_transcription",
    "data": {
        "text": "éƒ¨åˆ†è¯†åˆ«å†…å®¹",
        "confidence": 0.85,
        "isPartial": true,
        "timestamp": 1704067200000
    }
}
```

#### **æœ€ç»ˆè¯†åˆ«ç»“æœ**
```json
{
    "type": "final_transcription",
    "data": {
        "text": "å®Œæ•´è¯†åˆ«å†…å®¹",
        "partialCount": 3,
        "totalDuration": 5000
    }
}
```

#### **å®Œæ•´ç»“æœï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰**
```json
{
    "type": "complete_result",
    "data": {
        "transcription": {
            "text": "æ‚¨è¯´çš„å†…å®¹",
            "confidence": 0.95,
            "language": "zh_cn",
            "duration": 2500
        },
        "aiResponse": {
            "message": "Kimiçš„æ™ºèƒ½å›å¤",
            "usage": {
                "prompt_tokens": 10,
                "completion_tokens": 50,
                "total_tokens": 60
            },
            "model": "moonshot-v1-8k"
        },
        "conversationHistory": [
            {"role": "user", "content": "æ‚¨è¯´çš„å†…å®¹"},
            {"role": "assistant", "content": "Kimiçš„æ™ºèƒ½å›å¤"}
        ],
        "processingTime": 3500
    }
}
```

#### **æµå¼å®Œæ•´ç»“æœ**
```json
{
    "type": "stream_complete_result",
    "data": {
        "transcription": {
            "text": "æœ€ç»ˆåˆå¹¶çš„è¯†åˆ«å†…å®¹",
            "partialResults": [
                {"text": "éƒ¨åˆ†1", "timestamp": 1704067200000},
                {"text": "éƒ¨åˆ†2", "timestamp": 1704067202000}
            ],
            "totalDuration": 5000
        },
        "aiResponse": {
            "message": "Kimiçš„æ™ºèƒ½å›å¤",
            "usage": {...},
            "model": "moonshot-v1-8k"
        },
        "conversationHistory": [...],
        "processingTime": 5500
    }
}
```

#### **é”™è¯¯æ¶ˆæ¯**
```json
{
    "type": "error",
    "error": "é”™è¯¯æè¿°ä¿¡æ¯"
}
```

## ğŸ¤ å‰ç«¯å½•éŸ³å®ç°

### **è·å–éº¦å…‹é£æƒé™**
```javascript
async function setupMicrophone() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                sampleRate: 16000,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true
            }
        });
        
        mediaRecorder = new MediaRecorder(stream, {
            mimeType: 'audio/webm;codecs=opus'
        });
        
        return true;
    } catch (error) {
        console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
        return false;
    }
}
```

### **å½•éŸ³æŒ‰é’®å®ç°**
```javascript
const recordButton = document.getElementById('recordButton');

// æŒ‰ä¸‹å¼€å§‹å½•éŸ³
recordButton.addEventListener('mousedown', () => {
    startRecording();
});

// æ¾å¼€åœæ­¢å½•éŸ³
recordButton.addEventListener('mouseup', () => {
    stopRecording();
});

// å¤„ç†è§¦æ‘¸è®¾å¤‡
recordButton.addEventListener('touchstart', (e) => {
    e.preventDefault();
    startRecording();
});

recordButton.addEventListener('touchend', (e) => {
    e.preventDefault();
    stopRecording();
});
```

## ğŸ“± Reacté›†æˆç¤ºä¾‹

```jsx
import React, { useState, useEffect, useRef } from 'react';

const VoiceChat = () => {
    const [ws, setWs] = useState(null);
    const [isRecording, setIsRecording] = useState(false);
    const [status, setStatus] = useState('disconnected');
    const [messages, setMessages] = useState([]);
    const [currentTranscription, setCurrentTranscription] = useState('');
    const [streamMode, setStreamMode] = useState(true);
    const mediaRecorderRef = useRef(null);

    useEffect(() => {
        // åˆå§‹åŒ–WebSocket
        const websocket = new WebSocket('ws://localhost:3000/api/realtime-voice');
        
        websocket.onopen = () => {
            setStatus('connected');
            setWs(websocket);
        };
        
        websocket.onmessage = (event) => {
            const message = JSON.parse(event.data);
            handleMessage(message);
        };
        
        websocket.onclose = () => {
            setStatus('disconnected');
        };

        return () => {
            websocket.close();
        };
    }, []);

    const handleMessage = (message) => {
        switch (message.type) {
            case 'complete_result':
            case 'stream_complete_result':
                setMessages(prev => [
                    ...prev,
                    { type: 'user', content: message.data.transcription.text },
                    { type: 'assistant', content: message.data.aiResponse.message }
                ]);
                break;
            case 'stream_transcription':
                // æ˜¾ç¤ºå®æ—¶è¯†åˆ«ç»“æœ
                setCurrentTranscription(message.data.text);
                break;
            case 'final_transcription':
                // æ¸…é™¤å®æ—¶è¯†åˆ«ï¼Œæ˜¾ç¤ºæœ€ç»ˆç»“æœ
                setCurrentTranscription('');
                break;
            case 'error':
                console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', message.error);
                break;
        }
    };

    const toggleRecording = async () => {
        if (!ws || ws.readyState !== WebSocket.OPEN) return;

        if (isRecording) {
            // åœæ­¢å½•éŸ³
            if (mediaRecorderRef.current) {
                mediaRecorderRef.current.stop();
            }
            
            if (streamMode) {
                ws.send(JSON.stringify({ type: 'toggle_recording' }));
            } else {
                ws.send(JSON.stringify({ type: 'stop_recording' }));
            }
            
            setIsRecording(false);
        } else {
            // å¼€å§‹å½•éŸ³
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const mediaRecorder = new MediaRecorder(stream);
                mediaRecorderRef.current = mediaRecorder;

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        ws.send(event.data);
                    }
                };

                // å‘é€å¼€å§‹å½•éŸ³æ¶ˆæ¯
                ws.send(JSON.stringify({
                    type: streamMode ? 'toggle_recording' : 'start_recording',
                    language: 'zh_cn',
                    model: 'moonshot-v1-8k',
                    streamMode: streamMode
                }));

                mediaRecorder.start(100);
                setIsRecording(true);
            } catch (error) {
                console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
            }
        }
    };

    return (
        <div>
            <div>çŠ¶æ€: {status}</div>
            
            <div>
                <label>
                    <input 
                        type="checkbox" 
                        checked={streamMode} 
                        onChange={(e) => setStreamMode(e.target.checked)} 
                    />
                    å®æ—¶æµå¼è¯†åˆ«
                </label>
            </div>
            
            <button
                onClick={toggleRecording}
                disabled={status !== 'connected'}
                style={{
                    backgroundColor: isRecording ? 'red' : 'green',
                    color: 'white',
                    border: 'none',
                    borderRadius: '50%',
                    width: '100px',
                    height: '100px',
                    fontSize: '24px'
                }}
            >
                {isRecording ? (streamMode ? 'â¹ï¸' : 'ğŸ”´') : 'ğŸ¤'}
            </button>
            
            <div>{streamMode ? 'ç‚¹å‡»å½•éŸ³ï¼Œå®æ—¶è¯†åˆ«' : 'æŒ‰ä½å½•éŸ³ï¼Œæ¾å¼€å¤„ç†'}</div>

            <div>
                {currentTranscription && (
                    <div style={{
                        padding: '10px',
                        margin: '5px',
                        backgroundColor: '#fff3cd',
                        borderRadius: '8px',
                        fontStyle: 'italic',
                        border: '2px dashed #ffc107'
                    }}>
                        <strong>ğŸ‘¤ æ‚¨ (å®æ—¶):</strong> {currentTranscription}
                    </div>
                )}
                
                {messages.map((msg, index) => (
                    <div key={index} style={{
                        padding: '10px',
                        margin: '5px',
                        backgroundColor: msg.type === 'user' ? '#e3f2fd' : '#f1f8e9',
                        borderRadius: '8px'
                    }}>
                        <strong>{msg.type === 'user' ? 'ğŸ‘¤ æ‚¨' : 'ğŸ¤– Kimi'}:</strong> {msg.content}
                    </div>
                ))}
            </div>
        </div>
    );
};

export default VoiceChat;
```

## ğŸ¯ Vue.jsé›†æˆç¤ºä¾‹

```vue
<template>
  <div class="voice-chat">
    <div class="status">çŠ¶æ€: {{ status }}</div>
    
    <button
      @mousedown="startRecording"
      @mouseup="stopRecording"
      :disabled="status !== 'connected'"
      :class="{ recording: isRecording }"
      class="record-button"
    >
      {{ isRecording ? 'ğŸ”´' : 'ğŸ¤' }}
    </button>

    <div class="messages">
      <div
        v-for="(message, index) in messages"
        :key="index"
        :class="['message', message.type]"
      >
        <strong>{{ message.type === 'user' ? 'ğŸ‘¤ æ‚¨' : 'ğŸ¤– Kimi' }}:</strong>
        {{ message.content }}
      </div>
    </div>
  </div>
</template>

<script>
export default {
  name: 'VoiceChat',
  data() {
    return {
      ws: null,
      isRecording: false,
      status: 'disconnected',
      messages: [],
      mediaRecorder: null
    };
  },
  mounted() {
    this.initWebSocket();
  },
  beforeDestroy() {
    if (this.ws) {
      this.ws.close();
    }
  },
  methods: {
    initWebSocket() {
      this.ws = new WebSocket('ws://localhost:3000/api/realtime-voice');
      
      this.ws.onopen = () => {
        this.status = 'connected';
      };
      
      this.ws.onmessage = (event) => {
        const message = JSON.parse(event.data);
        this.handleMessage(message);
      };
      
      this.ws.onclose = () => {
        this.status = 'disconnected';
      };
    },
    
    handleMessage(message) {
      if (message.type === 'complete_result') {
        this.messages.push(
          { type: 'user', content: message.data.transcription.text },
          { type: 'assistant', content: message.data.aiResponse.message }
        );
      }
    },
    
    async startRecording() {
      if (!this.ws || this.ws.readyState !== WebSocket.OPEN) return;

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        this.mediaRecorder = new MediaRecorder(stream);

        this.mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            this.ws.send(event.data);
          }
        };

        this.ws.send(JSON.stringify({
          type: 'start_recording',
          language: 'zh_cn',
          model: 'moonshot-v1-8k'
        }));

        this.mediaRecorder.start(100);
        this.isRecording = true;
      } catch (error) {
        console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
      }
    },
    
    stopRecording() {
      if (this.mediaRecorder) {
        this.mediaRecorder.stop();
      }
      
      if (this.ws) {
        this.ws.send(JSON.stringify({ type: 'stop_recording' }));
      }
      
      this.isRecording = false;
    }
  }
};
</script>

<style>
.record-button {
  width: 100px;
  height: 100px;
  border-radius: 50%;
  border: none;
  background: green;
  color: white;
  font-size: 24px;
  cursor: pointer;
}

.record-button.recording {
  background: red;
  animation: pulse 1s infinite;
}

@keyframes pulse {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.1); }
}

.message.user {
  background: #e3f2fd;
  text-align: right;
}

.message.assistant {
  background: #f1f8e9;
}
</style>
```

## ğŸ”§ é…ç½®é€‰é¡¹

### **è¯­è¨€æ”¯æŒ**
- `zh_cn`: ä¸­æ–‡
- `en_us`: è‹±æ–‡

### **AIæ¨¡å‹**
- `moonshot-v1-8k`: 8Kä¸Šä¸‹æ–‡
- `moonshot-v1-32k`: 32Kä¸Šä¸‹æ–‡  
- `moonshot-v1-128k`: 128Kä¸Šä¸‹æ–‡

### **éŸ³é¢‘è®¾ç½®**
- é‡‡æ ·ç‡: 16kHz (æ¨è)
- å£°é“: å•å£°é“
- æ ¼å¼: WebM/Opus

## ğŸš€ å¼€å§‹ä½¿ç”¨

1. **ç¡®ä¿åç«¯æœåŠ¡è¿è¡Œ**: `npm start`
2. **æ‰“å¼€æµ‹è¯•é¡µé¢**: `frontend-examples/realtime-voice-chat.html`
3. **å…è®¸éº¦å…‹é£æƒé™**
4. **æŒ‰ä½å½•éŸ³æŒ‰é’®å¼€å§‹å¯¹è¯**

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœåœ¨é›†æˆè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€
2. ç¡®è®¤éº¦å…‹é£æƒé™å·²æˆäºˆ
3. æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°é”™è¯¯ä¿¡æ¯
4. æµ‹è¯•ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å™¨çŠ¶æ€

**ç°åœ¨æ‚¨çš„å‰ç«¯åŒäº‹å¯ä»¥è½»æ¾é›†æˆå®æ—¶å½•éŸ³è¯­éŸ³å¯¹è¯åŠŸèƒ½äº†ï¼** ğŸ‰