const KimiService = require('./kimiService');
const XunfeiAudioService = require('./xunfeiAudioService');

/**
 * éŸ³é¢‘è½¬æ–‡å­— + Kimiå¯¹è¯é›†æˆæœåŠ¡
 * åŸºäºè®¯é£è¯­éŸ³è¯†åˆ«APIå’ŒKimi AIçš„å®Œæ•´è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
 */
class AudioToKimiService {
  constructor() {
    this.kimiService = new KimiService();
    this.xunfeiService = new XunfeiAudioService();
    
    this.audioConfig = {
      provider: 'xunfei',
      language: 'zh_cn',
      timeout: 30000
    };
  }

  /**
   * å¤„ç†è¯­éŸ³æ–‡ä»¶å¹¶ç”ŸæˆAIå›å¤
   * @param {Buffer|File} audioData - éŸ³é¢‘æ•°æ®
   * @param {Object} options - é€‰é¡¹é…ç½®
   * @returns {Promise<Object>} å®Œæ•´çš„å¤„ç†ç»“æœ
   */
  async processVoiceToChat(audioData, options = {}) {
    try {
      console.log('ğŸ¤ å¼€å§‹è®¯é£è¯­éŸ³å¯¹è¯æµç¨‹...');
      
      // ç¬¬ä¸€æ­¥ï¼šè®¯é£è¯­éŸ³è½¬æ–‡å­—
      console.log('ğŸ“ æ­¥éª¤1: è®¯é£è¯­éŸ³è¯†åˆ«...');
      const transcriptionResult = await this.transcribeAudio(audioData, options);
      
      if (!transcriptionResult.success) {
        return {
          success: false,
          error: 'è®¯é£è¯­éŸ³è¯†åˆ«å¤±è´¥: ' + transcriptionResult.error,
          step: 'transcription'
        };
      }

      const transcribedText = transcriptionResult.text;
      console.log(`âœ… è®¯é£è¯†åˆ«ç»“æœ: "${transcribedText}"`);

      // ç¬¬äºŒæ­¥ï¼šå‘é€ç»™Kimi AI
      console.log('ğŸ¤– æ­¥éª¤2: Kimi AIå¯¹è¯å¤„ç†...');
      const chatResult = await this.kimiService.chatCompletion(
        transcribedText,
        options.model || 'moonshot-v1-8k'
      );

      if (!chatResult.success) {
        return {
          success: false,
          error: 'Kimi AIå¯¹è¯å¤±è´¥: ' + chatResult.error,
          step: 'chat',
          transcription: transcriptionResult
        };
      }

      console.log('âœ… Kimi AIå›å¤ç”Ÿæˆå®Œæˆ');

      // è¿”å›å®Œæ•´ç»“æœ
      return {
        success: true,
        data: {
          transcription: {
            text: transcribedText,
            confidence: transcriptionResult.confidence,
            language: transcriptionResult.language,
            duration: transcriptionResult.duration,
            provider: 'xunfei'
          },
          aiResponse: {
            message: chatResult.data.message,
            usage: chatResult.data.usage,
            model: chatResult.data.model
          },
          workflow: 'xunfei-voice-to-kimi-ai',
          processingTime: Date.now() - (options.startTime || Date.now())
        }
      };

    } catch (error) {
      console.error('âŒ è®¯é£è¯­éŸ³å¯¹è¯æµç¨‹é”™è¯¯:', error);
      return {
        success: false,
        error: error.message || 'è¯­éŸ³å¯¹è¯å¤„ç†å¤±è´¥',
        step: 'unknown'
      };
    }
  }

  /**
   * å¤šè½®è¯­éŸ³å¯¹è¯
   * @param {Buffer|File} audioData - éŸ³é¢‘æ•°æ®
   * @param {Array} conversationHistory - å¯¹è¯å†å²
   * @param {Object} options - é€‰é¡¹é…ç½®
   * @returns {Promise<Object>} å¤„ç†ç»“æœ
   */
  async processVoiceToContextualChat(audioData, conversationHistory = [], options = {}) {
    try {
      console.log('ğŸ¤ å¼€å§‹å¤šè½®è®¯é£è¯­éŸ³å¯¹è¯...');
      
      // ç¬¬ä¸€æ­¥ï¼šè®¯é£è¯­éŸ³è½¬æ–‡å­—
      const transcriptionResult = await this.transcribeAudio(audioData, options);
      
      if (!transcriptionResult.success) {
        return {
          success: false,
          error: 'è®¯é£è¯­éŸ³è¯†åˆ«å¤±è´¥: ' + transcriptionResult.error
        };
      }

      // ç¬¬äºŒæ­¥ï¼šæ„å»ºå¯¹è¯å†å²
      const messages = [
        ...conversationHistory,
        {
          role: 'user',
          content: transcriptionResult.text
        }
      ];

      // ç¬¬ä¸‰æ­¥ï¼šå‘é€ç»™Kimi AI
      const chatResult = await this.kimiService.chatWithHistory(
        messages,
        options.model || 'moonshot-v1-8k'
      );

      if (!chatResult.success) {
        return {
          success: false,
          error: 'Kimi AIå¯¹è¯å¤±è´¥: ' + chatResult.error,
          transcription: transcriptionResult
        };
      }

      // æ›´æ–°å¯¹è¯å†å²
      const updatedHistory = [
        ...messages,
        {
          role: 'assistant',
          content: chatResult.data.message
        }
      ];

      return {
        success: true,
        data: {
          transcription: transcriptionResult,
          aiResponse: chatResult.data,
          conversationHistory: updatedHistory,
          workflow: 'contextual-xunfei-voice-chat'
        }
      };

    } catch (error) {
      console.error('âŒ å¤šè½®è®¯é£è¯­éŸ³å¯¹è¯é”™è¯¯:', error);
      return {
        success: false,
        error: error.message
      };
    }
  }

  /**
   * æµå¼è¯­éŸ³å¯¹è¯å¤„ç†
   * @param {Buffer|File} audioData - éŸ³é¢‘æ•°æ®
   * @param {Object} options - é€‰é¡¹
   */
  async processVoiceToStreamChat(audioData, options = {}) {
    const { onTranscription, onAIResponse, onComplete, onError } = options;

    try {
      // ç¬¬ä¸€æ­¥ï¼šè®¯é£è¯­éŸ³è½¬æ–‡å­—
      const transcriptionResult = await this.transcribeAudio(audioData, options);
      
      if (!transcriptionResult.success) {
        onError && onError(new Error('è®¯é£è¯­éŸ³è¯†åˆ«å¤±è´¥: ' + transcriptionResult.error));
        return;
      }

      // é€šçŸ¥è¯­éŸ³è¯†åˆ«å®Œæˆ
      onTranscription && onTranscription(transcriptionResult);

      // ç¬¬äºŒæ­¥ï¼šæµå¼Kimi AIå¯¹è¯
      const streamResult = await this.kimiService.chatStream(transcriptionResult.text, options.model);

      if (!streamResult.success) {
        onError && onError(new Error('Kimi AIå¯¹è¯å¤±è´¥: ' + streamResult.error));
        return;
      }

      // å¤„ç†æµå¼å“åº”
      const stream = streamResult.stream;
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content && onAIResponse) {
          onAIResponse(content);
        }
      }

      onComplete && onComplete({
        transcription: transcriptionResult,
        workflow: 'stream-xunfei-voice-chat'
      });

    } catch (error) {
      onError && onError(error);
    }
  }

  /**
   * æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
   * @param {Array} audioFiles - éŸ³é¢‘æ–‡ä»¶æ•°ç»„
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<Array>} å¤„ç†ç»“æœæ•°ç»„
   */
  async processBatchVoiceToChat(audioFiles, options = {}) {
    const results = [];
    
    for (let i = 0; i < audioFiles.length; i++) {
      const audioFile = audioFiles[i];
      console.log(`ğŸ”„ å¤„ç†ç¬¬ ${i + 1}/${audioFiles.length} ä¸ªéŸ³é¢‘æ–‡ä»¶...`);
      
      try {
        const result = await this.processVoiceToChat(audioFile.buffer || audioFile, {
          ...options,
          startTime: Date.now()
        });
        
        results.push({
          index: i,
          filename: audioFile.filename || `audio_${i}`,
          result
        });
        
      } catch (error) {
        results.push({
          index: i,
          filename: audioFile.filename || `audio_${i}`,
          result: {
            success: false,
            error: error.message
          }
        });
      }
    }
    
    return results;
  }

  /**
   * è®¯é£è¯­éŸ³è½¬æ–‡å­—å¤„ç† - æ ¸å¿ƒé›†æˆæ–¹æ³•
   * @param {Buffer|File} audioData - éŸ³é¢‘æ•°æ®
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<Object>} è½¬å½•ç»“æœ
   */
  async transcribeAudio(audioData, options = {}) {
    try {
      console.log('ğŸ¤ è°ƒç”¨è®¯é£è¯­éŸ³è¯†åˆ«...');
      
      // å¤„ç†éŸ³é¢‘æ•°æ®
      let audioBuffer;
      if (Buffer.isBuffer(audioData)) {
        audioBuffer = audioData;
      } else if (audioData.buffer) {
        audioBuffer = audioData.buffer;
      } else {
        throw new Error('æ— æ•ˆçš„éŸ³é¢‘æ•°æ®æ ¼å¼');
      }

      // è°ƒç”¨è®¯é£è¯­éŸ³è¯†åˆ«æœåŠ¡
      const result = await this.xunfeiService.transcribe(audioBuffer, {
        language: options.language || 'zh_cn'
      });

      return {
        success: true,
        text: result.text,
        confidence: result.confidence,
        language: result.language,
        duration: result.duration,
        provider: result.provider
      };

    } catch (error) {
      console.error('è®¯é£è¯­éŸ³è½¬æ–‡å­—é”™è¯¯:', error);
      return {
        success: false,
        error: error.message || 'è®¯é£è¯­éŸ³è¯†åˆ«å¤±è´¥'
      };
    }
  }

  /**
   * æµ‹è¯•è®¯é£APIå’ŒKimi APIçš„é›†æˆ
   * @returns {Promise<Object>} æµ‹è¯•ç»“æœ
   */
  async testIntegration() {
    try {
      console.log('ğŸ§ª å¼€å§‹é›†æˆæµ‹è¯•...');
      
      // 1. æµ‹è¯•è®¯é£APIè¿æ¥
      console.log('1ï¸âƒ£ æµ‹è¯•è®¯é£API...');
      const xunfeiTest = await this.xunfeiService.testConnection();
      
      if (!xunfeiTest.success) {
        return {
          success: false,
          error: 'è®¯é£APIæµ‹è¯•å¤±è´¥: ' + xunfeiTest.message,
          details: { xunfei: xunfeiTest }
        };
      }

      // 2. æµ‹è¯•Kimi APIè¿æ¥
      console.log('2ï¸âƒ£ æµ‹è¯•Kimi API...');
      const kimiTest = await this.kimiService.chatCompletion('æµ‹è¯•è¿æ¥', 'moonshot-v1-8k');
      
      if (!kimiTest.success) {
        return {
          success: false,
          error: 'Kimi APIæµ‹è¯•å¤±è´¥: ' + kimiTest.error,
          details: { xunfei: xunfeiTest, kimi: kimiTest }
        };
      }

      console.log('âœ… é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡');
      
      return {
        success: true,
        message: 'è®¯é£è¯­éŸ³è¯†åˆ«+Kimi AIé›†æˆæµ‹è¯•æˆåŠŸ',
        details: {
          xunfei: xunfeiTest,
          kimi: {
            success: true,
            message: 'Kimi APIè¿æ¥æ­£å¸¸',
            response: kimiTest.data.message.substring(0, 50) + '...'
          },
          integration: 'ready'
        }
      };

    } catch (error) {
      console.error('âŒ é›†æˆæµ‹è¯•å¤±è´¥:', error);
      return {
        success: false,
        error: 'é›†æˆæµ‹è¯•å¤±è´¥: ' + error.message
      };
    }
  }

  /**
   * è·å–æœåŠ¡çŠ¶æ€å’Œé…ç½®ä¿¡æ¯
   * @returns {Object} æœåŠ¡çŠ¶æ€
   */
  getServiceStatus() {
    return {
      audioService: this.xunfeiService.getStatus(),
      kimiService: 'initialized',
      integration: 'xunfei + kimi',
      supportedLanguages: ['zh_cn', 'en_us'],
      maxAudioSize: '50MB',
      supportedFormats: ['wav', 'mp3', 'm4a', 'flac'],
      workflow: [
        '1. éŸ³é¢‘ä¸Šä¼ ',
        '2. è®¯é£è¯­éŸ³è¯†åˆ«',
        '3. Kimi AIå¯¹è¯',
        '4. è¿”å›ç»“æœ'
      ]
    };
  }
}

module.exports = AudioToKimiService;