const WebSocket = require('ws');
const XunfeiAudioService = require('./xunfeiAudioService');
const KimiService = require('./kimiService');

/**
 * å®æ—¶è¯­éŸ³è¯†åˆ«WebSocketæœåŠ¡
 * æ”¯æŒå‰ç«¯å®æ—¶å½•éŸ³ï¼Œåç«¯å®æ—¶è½¬æ–‡å­—å¹¶å¤„ç†
 */
class RealtimeVoiceService {
  constructor() {
    this.xunfeiService = new XunfeiAudioService();
    this.kimiService = new KimiService();
    this.activeSessions = new Map(); // å­˜å‚¨æ´»è·ƒçš„è¯­éŸ³ä¼šè¯
  }

  /**
   * åˆ›å»ºWebSocketæœåŠ¡å™¨
   * @param {Object} server - HTTPæœåŠ¡å™¨å®ä¾‹
   */
  createWebSocketServer(server) {
    const wss = new WebSocket.Server({ 
      server,
      path: '/api/realtime-voice'
    });

    wss.on('connection', (ws, req) => {
      console.log('ğŸ¤ æ–°çš„å®æ—¶è¯­éŸ³è¿æ¥å»ºç«‹');
      
      const sessionId = this.generateSessionId();
      const session = {
        id: sessionId,
        ws: ws,
        audioBuffer: Buffer.alloc(0),
        isRecording: false,
        isStreamMode: false,
        streamBuffer: Buffer.alloc(0),
        lastProcessTime: 0,
        partialResults: [],
        conversationHistory: [],
        language: 'zh_cn',
        model: 'moonshot-v1-8k',
        startTime: Date.now(),
        xunfeiConnection: null,
        streamInterval: null
      };

      this.activeSessions.set(sessionId, session);

      // å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
      this.sendMessage(ws, {
        type: 'connected',
        sessionId: sessionId,
        message: 'å®æ—¶è¯­éŸ³è¯†åˆ«è¿æ¥å·²å»ºç«‹'
      });

      // å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
      ws.on('message', async (data) => {
        try {
          await this.handleClientMessage(sessionId, data);
        } catch (error) {
          console.error('å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯å¤±è´¥:', error);
          this.sendError(ws, 'å¤„ç†æ¶ˆæ¯å¤±è´¥: ' + error.message);
        }
      });

      // å¤„ç†è¿æ¥å…³é—­
      ws.on('close', () => {
        console.log(`ğŸ”’ å®æ—¶è¯­éŸ³è¿æ¥å…³é—­: ${sessionId}`);
        this.activeSessions.delete(sessionId);
      });

      // å¤„ç†è¿æ¥é”™è¯¯
      ws.on('error', (error) => {
        console.error(`âŒ WebSocketé”™è¯¯ ${sessionId}:`, error);
        this.activeSessions.delete(sessionId);
      });
    });

    console.log('ğŸŒ å®æ—¶è¯­éŸ³WebSocketæœåŠ¡å™¨å·²å¯åŠ¨: /api/realtime-voice');
    return wss;
  }

  /**
   * å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Buffer|string} data - å®¢æˆ·ç«¯æ•°æ®
   */
  async handleClientMessage(sessionId, data) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    try {
      // å°è¯•è§£æJSONæ¶ˆæ¯
      const message = JSON.parse(data.toString());
      await this.handleControlMessage(sessionId, message);
    } catch (e) {
      // å¦‚æœä¸æ˜¯JSONï¼Œå½“ä½œéŸ³é¢‘æ•°æ®å¤„ç†
      await this.handleAudioData(sessionId, data);
    }
  }

  /**
   * å¤„ç†æ§åˆ¶æ¶ˆæ¯
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} message - æ§åˆ¶æ¶ˆæ¯
   */
  async handleControlMessage(sessionId, message) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    switch (message.type) {
      case 'start_recording':
        await this.startRecording(sessionId, message);
        break;
      
      case 'stop_recording':
        await this.stopRecording(sessionId);
        break;
      
      case 'toggle_recording':
        await this.toggleRecording(sessionId, message);
        break;
      
      case 'config':
        this.updateConfig(sessionId, message);
        break;
      
      case 'clear_history':
        this.clearHistory(sessionId);
        break;
      
      default:
        console.log(`æœªçŸ¥æ¶ˆæ¯ç±»å‹: ${message.type}`);
    }
  }

  /**
   * å¼€å§‹å½•éŸ³
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} config - å½•éŸ³é…ç½®
   */
  async startRecording(sessionId, config = {}) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    session.isRecording = true;
    session.isStreamMode = config.streamMode || false;
    session.audioBuffer = Buffer.alloc(0);
    session.streamBuffer = Buffer.alloc(0);
    session.lastProcessTime = Date.now();
    session.partialResults = [];
    session.language = config.language || 'zh_cn';
    session.model = config.model || 'moonshot-v1-8k';
    session.startTime = Date.now();

    this.sendMessage(session.ws, {
      type: 'recording_started',
      message: session.isStreamMode ? 'å¼€å§‹å®æ—¶å½•éŸ³' : 'å¼€å§‹å½•éŸ³',
      config: {
        language: session.language,
        model: session.model,
        streamMode: session.isStreamMode
      }
    });

    // å¦‚æœæ˜¯æµå¼æ¨¡å¼ï¼Œå¯åŠ¨å®æ—¶å¤„ç†
    if (session.isStreamMode) {
      await this.startStreamProcessing(sessionId);
    }

    console.log(`ğŸ¤ å¼€å§‹${session.isStreamMode ? 'å®æ—¶' : ''}å½•éŸ³: ${sessionId}`);
  }

  /**
   * åˆ‡æ¢å½•éŸ³çŠ¶æ€
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} config - é…ç½®å‚æ•°
   */
  async toggleRecording(sessionId, config = {}) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    if (session.isRecording) {
      // å½“å‰æ­£åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
      await this.stopRecording(sessionId);
    } else {
      // å½“å‰æœªå½•éŸ³ï¼Œå¼€å§‹å½•éŸ³
      config.streamMode = true; // åˆ‡æ¢æ¨¡å¼é»˜è®¤å¼€å¯æµå¼å¤„ç†
      await this.startRecording(sessionId, config);
    }
  }

  /**
   * å¼€å§‹å®æ—¶æµå¼å¤„ç†
   * @param {string} sessionId - ä¼šè¯ID
   */
  async startStreamProcessing(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    // è®¾ç½®å®šæ—¶å™¨ï¼Œæ¯2ç§’å¤„ç†ä¸€æ¬¡ç´¯ç§¯çš„éŸ³é¢‘
    session.streamInterval = setInterval(async () => {
      await this.processStreamAudio(sessionId);
    }, 2000);

    console.log(`ğŸŒŠ å¼€å§‹å®æ—¶æµå¼å¤„ç†: ${sessionId}`);
  }

  /**
   * å¤„ç†æµå¼éŸ³é¢‘ç‰‡æ®µ
   * @param {string} sessionId - ä¼šè¯ID
   */
  async processStreamAudio(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session || !session.isRecording || !session.isStreamMode) return;

    // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®ï¼ˆè‡³å°‘1ç§’çš„éŸ³é¢‘ï¼‰
    const minAudioSize = 16000 * 2; // 16kHz * 2å­—èŠ‚ * 1ç§’
    if (session.streamBuffer.length < minAudioSize) return;

    try {
      // å‘é€å¤„ç†çŠ¶æ€
      this.sendMessage(session.ws, {
        type: 'stream_processing',
        message: 'å®æ—¶å¤„ç†ä¸­...',
        audioSize: session.streamBuffer.length
      });

      // è½¬æ¢éŸ³é¢‘ä¸ºWAVæ ¼å¼
      const audioBuffer = this.convertToWav(session.streamBuffer);
      
      // è°ƒç”¨è®¯é£è¯†åˆ«
      const transcriptionResult = await this.xunfeiService.transcribe(audioBuffer, {
        language: session.language
      });

      if (transcriptionResult.success && transcriptionResult.text.trim()) {
        const transcribedText = transcriptionResult.text.trim();
        
        // ä¸å‘é€å®æ—¶è¯†åˆ«ç»“æœåˆ°å‰ç«¯ï¼Œåªè®°å½•åœ¨åç«¯
        // this.sendMessage(session.ws, {
        //   type: 'stream_transcription',
        //   data: {
        //     text: transcribedText,
        //     confidence: transcriptionResult.confidence,
        //     isPartial: true,
        //     timestamp: Date.now()
        //   }
        // });

        // ä¿å­˜éƒ¨åˆ†ç»“æœ
        session.partialResults.push({
          text: transcribedText,
          timestamp: Date.now(),
          confidence: transcriptionResult.confidence
        });

        console.log(`ğŸ“ å®æ—¶è¯†åˆ«: "${transcribedText}"`);
      }

      // æ¸…ç©ºå·²å¤„ç†çš„æµå¼ç¼“å†²åŒº
      session.streamBuffer = Buffer.alloc(0);
      session.lastProcessTime = Date.now();

    } catch (error) {
      console.error('å®æ—¶æµå¼å¤„ç†å¤±è´¥:', error);
      this.sendMessage(session.ws, {
        type: 'stream_error',
        error: 'å®æ—¶å¤„ç†å¤±è´¥: ' + error.message
      });
    }
  }

  /**
   * åœæ­¢å½•éŸ³å¹¶å¤„ç†
   * @param {string} sessionId - ä¼šè¯ID
   */
  async stopRecording(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session || !session.isRecording) return;

    session.isRecording = false;

    // åœæ­¢æµå¼å¤„ç†å®šæ—¶å™¨
    if (session.streamInterval) {
      clearInterval(session.streamInterval);
      session.streamInterval = null;
    }

    this.sendMessage(session.ws, {
      type: 'recording_stopped',
      message: session.isStreamMode ? 'å®æ—¶å½•éŸ³ç»“æŸï¼Œç”Ÿæˆæœ€ç»ˆå›å¤...' : 'å½•éŸ³ç»“æŸï¼Œå¤„ç†ä¸­...',
      streamMode: session.isStreamMode
    });

    console.log(`ğŸ›‘ åœæ­¢${session.isStreamMode ? 'å®æ—¶' : ''}å½•éŸ³: ${sessionId}, éŸ³é¢‘å¤§å°: ${session.audioBuffer.length} å­—èŠ‚`);

    // å¤„ç†å½•éŸ³æ•°æ®
    if (session.isStreamMode) {
      await this.processFinalStreamResult(sessionId);
    } else if (session.audioBuffer.length > 0) {
      await this.processRecordedAudio(sessionId);
    } else {
      this.sendError(session.ws, 'å½•éŸ³æ•°æ®ä¸ºç©º');
    }
  }

  /**
   * å¤„ç†æµå¼æ¨¡å¼çš„æœ€ç»ˆç»“æœ
   * @param {string} sessionId - ä¼šè¯ID
   */
  async processFinalStreamResult(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    try {
      // åˆå¹¶æ‰€æœ‰éƒ¨åˆ†è¯†åˆ«ç»“æœ
      let finalText = '';
      if (session.partialResults.length > 0) {
        // å–æœ€åå‡ ä¸ªç»“æœï¼Œå»é‡å¹¶åˆå¹¶
        const recentResults = session.partialResults.slice(-3);
        const uniqueTexts = [...new Set(recentResults.map(r => r.text))];
        finalText = uniqueTexts.join(' ');
      }

      // å¦‚æœæ²¡æœ‰æµå¼ç»“æœï¼Œå¤„ç†æœ€åçš„éŸ³é¢‘ç¼“å†²åŒº
      if (!finalText && session.audioBuffer.length > 0) {
        this.sendMessage(session.ws, {
          type: 'processing',
          step: 'final_transcription',
          message: 'å¤„ç†æœ€ç»ˆéŸ³é¢‘...'
        });

        const audioBuffer = this.convertToWav(session.audioBuffer);
        const transcriptionResult = await this.xunfeiService.transcribe(audioBuffer, {
          language: session.language
        });

        if (transcriptionResult.success) {
          finalText = transcriptionResult.text;
        }
      }

      if (!finalText || !finalText.trim()) {
        this.sendError(session.ws, 'æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹');
        return;
      }

      finalText = finalText.trim();
      console.log(`ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ: "${finalText}"`);

      // ä¸å‘é€æœ€ç»ˆè¯†åˆ«ç»“æœåˆ°å‰ç«¯ï¼Œåªè®°å½•åœ¨åç«¯
      // this.sendMessage(session.ws, {
      //   type: 'final_transcription',
      //   data: {
      //     text: finalText,
      //     partialCount: session.partialResults.length,
      //     totalDuration: Date.now() - session.startTime
      //   }
      // });

      // ç¬¬2æ­¥ï¼šKimi AIå¤„ç†
      this.sendMessage(session.ws, {
        type: 'processing',
        step: 'ai_response',
        message: 'æ­£åœ¨ç”ŸæˆAIå›å¤...'
      });

      // æ„å»ºå¯¹è¯å†å²
      const messages = [
        ...session.conversationHistory,
        { role: 'user', content: finalText }
      ];

      const chatResult = await this.kimiService.chatWithHistory(messages, session.model);

      if (!chatResult.success) {
        throw new Error('AIå¯¹è¯å¤±è´¥: ' + chatResult.error);
      }

      // æ›´æ–°å¯¹è¯å†å²
      session.conversationHistory = [
        ...messages,
        { role: 'assistant', content: chatResult.data.message }
      ];

      console.log('ğŸ¤– AIå›å¤ç”Ÿæˆå®Œæˆ');

      // å‘é€æœ€ç»ˆç»“æœ - åªå‘é€AIå›å¤ï¼Œä¸å‘é€è½¬å½•æ–‡å­—
      this.sendMessage(session.ws, {
        type: 'stream_complete_result',
        data: {
          aiResponse: {
            message: chatResult.data.message,
            usage: chatResult.data.usage,
            model: chatResult.data.model
          },
          conversationHistory: session.conversationHistory,
          processingTime: Date.now() - session.startTime
        }
      });

      // æ¸…ç†æµå¼æ•°æ®
      session.partialResults = [];
      session.streamBuffer = Buffer.alloc(0);

    } catch (error) {
      console.error('å¤„ç†æµå¼æœ€ç»ˆç»“æœå¤±è´¥:', error);
      this.sendError(session.ws, error.message);
    }
  }

  /**
   * å¤„ç†éŸ³é¢‘æ•°æ®
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Buffer} audioData - éŸ³é¢‘æ•°æ®
   */
  async handleAudioData(sessionId, audioData) {
    const session = this.activeSessions.get(sessionId);
    if (!session || !session.isRecording) return;

    // ç´¯ç§¯éŸ³é¢‘æ•°æ®
    session.audioBuffer = Buffer.concat([session.audioBuffer, audioData]);

    // å¦‚æœæ˜¯æµå¼æ¨¡å¼ï¼Œä¹Ÿç´¯ç§¯åˆ°æµå¼ç¼“å†²åŒº
    if (session.isStreamMode) {
      session.streamBuffer = Buffer.concat([session.streamBuffer, audioData]);
    }

    // å‘é€å½•éŸ³çŠ¶æ€æ›´æ–°
    this.sendMessage(session.ws, {
      type: 'recording_progress',
      audioSize: session.audioBuffer.length,
      duration: Date.now() - session.startTime,
      streamMode: session.isStreamMode
    });
  }

  /**
   * å¤„ç†å½•åˆ¶çš„éŸ³é¢‘
   * @param {string} sessionId - ä¼šè¯ID
   */
  async processRecordedAudio(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    try {
      // ç¬¬1æ­¥ï¼šè®¯é£è¯­éŸ³è¯†åˆ«
      this.sendMessage(session.ws, {
        type: 'processing',
        step: 'transcription',
        message: 'æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...'
      });

      const audioBuffer = this.convertToWav(session.audioBuffer);
      const transcriptionResult = await this.xunfeiService.transcribe(audioBuffer, {
        language: session.language
      });

      if (!transcriptionResult.success) {
        throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥: ' + transcriptionResult.error);
      }

      const transcribedText = transcriptionResult.text;
      console.log(`ğŸ“ è¯†åˆ«ç»“æœ: "${transcribedText}"`);

      // ä¸å‘é€è¯†åˆ«ç»“æœåˆ°å‰ç«¯ï¼Œåªè®°å½•åœ¨åç«¯
      // this.sendMessage(session.ws, {
      //   type: 'transcription_result',
      //   data: {
      //     text: transcribedText,
      //     confidence: transcriptionResult.confidence,
      //     language: transcriptionResult.language,
      //     duration: transcriptionResult.duration
      //   }
      // });

      // ç¬¬2æ­¥ï¼šKimi AIå¤„ç†
      this.sendMessage(session.ws, {
        type: 'processing',
        step: 'ai_response',
        message: 'æ­£åœ¨ç”ŸæˆAIå›å¤...'
      });

      // æ„å»ºå¯¹è¯å†å²
      const messages = [
        ...session.conversationHistory,
        { role: 'user', content: transcribedText }
      ];

      const chatResult = await this.kimiService.chatWithHistory(messages, session.model);

      if (!chatResult.success) {
        throw new Error('AIå¯¹è¯å¤±è´¥: ' + chatResult.error);
      }

      // æ›´æ–°å¯¹è¯å†å²
      session.conversationHistory = [
        ...messages,
        { role: 'assistant', content: chatResult.data.message }
      ];

      console.log('ğŸ¤– AIå›å¤ç”Ÿæˆå®Œæˆ');

      // å‘é€æœ€ç»ˆç»“æœ - åªå‘é€AIå›å¤ï¼Œä¸å‘é€è½¬å½•æ–‡å­—
      this.sendMessage(session.ws, {
        type: 'complete_result',
        data: {
          aiResponse: {
            message: chatResult.data.message,
            usage: chatResult.data.usage,
            model: chatResult.data.model
          },
          conversationHistory: session.conversationHistory,
          processingTime: Date.now() - session.startTime
        }
      });

    } catch (error) {
      console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error);
      this.sendError(session.ws, error.message);
    }
  }

  /**
   * è½¬æ¢éŸ³é¢‘ä¸ºWAVæ ¼å¼
   * @param {Buffer} audioBuffer - åŸå§‹éŸ³é¢‘æ•°æ®
   * @returns {Buffer} WAVæ ¼å¼éŸ³é¢‘
   */
  convertToWav(audioBuffer) {
    // å¦‚æœå·²ç»æ˜¯WAVæ ¼å¼ï¼Œç›´æ¥è¿”å›
    if (audioBuffer.length > 12 && 
        audioBuffer.toString('ascii', 0, 4) === 'RIFF' && 
        audioBuffer.toString('ascii', 8, 12) === 'WAVE') {
      return audioBuffer;
    }

    // ç®€å•çš„WAVå¤´éƒ¨æ„å»ºï¼ˆå‡è®¾16kHz, 16-bit, å•å£°é“ï¼‰
    const sampleRate = 16000;
    const bitsPerSample = 16;
    const channels = 1;
    const byteRate = sampleRate * channels * bitsPerSample / 8;
    const blockAlign = channels * bitsPerSample / 8;
    const dataSize = audioBuffer.length;
    const fileSize = 36 + dataSize;

    const header = Buffer.alloc(44);
    
    // RIFF chunk
    header.write('RIFF', 0);
    header.writeUInt32LE(fileSize, 4);
    header.write('WAVE', 8);
    
    // fmt chunk
    header.write('fmt ', 12);
    header.writeUInt32LE(16, 16);
    header.writeUInt16LE(1, 20);
    header.writeUInt16LE(channels, 22);
    header.writeUInt32LE(sampleRate, 24);
    header.writeUInt32LE(byteRate, 28);
    header.writeUInt16LE(blockAlign, 32);
    header.writeUInt16LE(bitsPerSample, 34);
    
    // data chunk
    header.write('data', 36);
    header.writeUInt32LE(dataSize, 40);

    return Buffer.concat([header, audioBuffer]);
  }

  /**
   * æ›´æ–°é…ç½®
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} config - æ–°é…ç½®
   */
  updateConfig(sessionId, config) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    if (config.language) session.language = config.language;
    if (config.model) session.model = config.model;

    this.sendMessage(session.ws, {
      type: 'config_updated',
      config: {
        language: session.language,
        model: session.model
      }
    });
  }

  /**
   * æ¸…é™¤å¯¹è¯å†å²
   * @param {string} sessionId - ä¼šè¯ID
   */
  clearHistory(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    session.conversationHistory = [];

    this.sendMessage(session.ws, {
      type: 'history_cleared',
      message: 'å¯¹è¯å†å²å·²æ¸…é™¤'
    });
  }

  /**
   * å‘é€æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
   * @param {WebSocket} ws - WebSocketè¿æ¥
   * @param {Object} message - æ¶ˆæ¯å¯¹è±¡
   */
  sendMessage(ws, message) {
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        ...message,
        timestamp: new Date().toISOString()
      }));
    }
  }

  /**
   * å‘é€é”™è¯¯æ¶ˆæ¯
   * @param {WebSocket} ws - WebSocketè¿æ¥
   * @param {string} error - é”™è¯¯ä¿¡æ¯
   */
  sendError(ws, error) {
    this.sendMessage(ws, {
      type: 'error',
      error: error
    });
  }

  /**
   * ç”Ÿæˆä¼šè¯ID
   * @returns {string} ä¼šè¯ID
   */
  generateSessionId() {
    return 'voice_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
  }

  /**
   * è·å–æ´»è·ƒä¼šè¯ç»Ÿè®¡
   * @returns {Object} ç»Ÿè®¡ä¿¡æ¯
   */
  getSessionStats() {
    return {
      activeSessions: this.activeSessions.size,
      sessions: Array.from(this.activeSessions.values()).map(session => ({
        id: session.id,
        isRecording: session.isRecording,
        audioBufferSize: session.audioBuffer.length,
        conversationLength: session.conversationHistory.length,
        uptime: Date.now() - session.startTime
      }))
    };
  }
}

module.exports = RealtimeVoiceService;