const WebSocket = require('ws');
const XunfeiAudioService = require('./xunfeiAudioService');
const KimiService = require('./kimiService');

/**
 * å®žæ—¶è¯­éŸ³è¯†åˆ«WebSocketæœåŠ¡
 * æ”¯æŒå‰ç«¯å®žæ—¶å½•éŸ³ï¼ŒåŽç«¯å®žæ—¶è½¬æ–‡å­—å¹¶å¤„ç†
 */
class RealtimeVoiceService {
  constructor() {
    this.xunfeiService = new XunfeiAudioService();
    this.kimiService = new KimiService();
    this.activeSessions = new Map(); // å­˜å‚¨æ´»è·ƒçš„è¯­éŸ³ä¼šè¯
  }

  /**
   * åˆ›å»ºWebSocketæœåŠ¡å™¨
   * @param {Object} server - HTTPæœåŠ¡å™¨å®žä¾‹
   */
  createWebSocketServer(server) {
    const wss = new WebSocket.Server({ 
      server,
      path: '/api/realtime-voice'
    });

    wss.on('connection', (ws, req) => {
      console.log('ðŸŽ¤ æ–°çš„å®žæ—¶è¯­éŸ³è¿žæŽ¥å»ºç«‹');
      
      const sessionId = this.generateSessionId();
      const session = {
        id: sessionId,
        ws: ws,
        audioBuffer: Buffer.alloc(0),
        isRecording: false,
        conversationHistory: [],
        language: 'zh_cn',
        model: 'moonshot-v1-8k',
        startTime: Date.now()
      };

      this.activeSessions.set(sessionId, session);

      // å‘é€è¿žæŽ¥æˆåŠŸæ¶ˆæ¯
      this.sendMessage(ws, {
        type: 'connected',
        sessionId: sessionId,
        message: 'å®žæ—¶è¯­éŸ³è¯†åˆ«è¿žæŽ¥å·²å»ºç«‹'
      });

      // å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
      ws.on('message', async (data) => {
        try {
          await this.handleClientMessage(sessionId, data);
        } catch (error) {
          console.error('å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯å¤±è´¥:', error);
          this.sendError(ws, 'å¤„ç†æ¶ˆæ¯å¤±è´¥: ' + error.message);
        }
      });

      // å¤„ç†è¿žæŽ¥å…³é—­
      ws.on('close', () => {
        console.log(`ðŸ”’ å®žæ—¶è¯­éŸ³è¿žæŽ¥å…³é—­: ${sessionId}`);
        this.activeSessions.delete(sessionId);
      });

      // å¤„ç†è¿žæŽ¥é”™è¯¯
      ws.on('error', (error) => {
        console.error(`âŒ WebSocketé”™è¯¯ ${sessionId}:`, error);
        this.activeSessions.delete(sessionId);
      });
    });

    console.log('ðŸŒ å®žæ—¶è¯­éŸ³WebSocketæœåŠ¡å™¨å·²å¯åŠ¨: /api/realtime-voice');
    return wss;
  }

  /**
   * å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Buffer|string} data - å®¢æˆ·ç«¯æ•°æ®
   */
  async handleClientMessage(sessionId, data) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    try {
      // å°è¯•è§£æžJSONæ¶ˆæ¯
      const message = JSON.parse(data.toString());
      await this.handleControlMessage(sessionId, message);
    } catch (e) {
      // å¦‚æžœä¸æ˜¯JSONï¼Œå½“ä½œéŸ³é¢‘æ•°æ®å¤„ç†
      await this.handleAudioData(sessionId, data);
    }
  }

  /**
   * å¤„ç†æŽ§åˆ¶æ¶ˆæ¯
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} message - æŽ§åˆ¶æ¶ˆæ¯
   */
  async handleControlMessage(sessionId, message) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    switch (message.type) {
      case 'start_recording':
        await this.startRecording(sessionId, message);
        break;
      
      case 'stop_recording':
        await this.stopRecording(sessionId);
        break;
      
      case 'config':
        this.updateConfig(sessionId, message);
        break;
      
      case 'clear_history':
        this.clearHistory(sessionId);
        break;
      
      default:
        console.log(`æœªçŸ¥æ¶ˆæ¯ç±»åž‹: ${message.type}`);
    }
  }

  /**
   * å¼€å§‹å½•éŸ³
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} config - å½•éŸ³é…ç½®
   */
  async startRecording(sessionId, config = {}) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    session.isRecording = true;
    session.audioBuffer = Buffer.alloc(0);
    session.language = config.language || 'zh_cn';
    session.model = config.model || 'moonshot-v1-8k';
    session.startTime = Date.now();

    this.sendMessage(session.ws, {
      type: 'recording_started',
      message: 'å¼€å§‹å½•éŸ³',
      config: {
        language: session.language,
        model: session.model
      }
    });

    console.log(`ðŸŽ¤ å¼€å§‹å½•éŸ³: ${sessionId}`);
  }

  /**
   * åœæ­¢å½•éŸ³å¹¶å¤„ç†
   * @param {string} sessionId - ä¼šè¯ID
   */
  async stopRecording(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session || !session.isRecording) return;

    session.isRecording = false;

    this.sendMessage(session.ws, {
      type: 'recording_stopped',
      message: 'å½•éŸ³ç»“æŸï¼Œå¤„ç†ä¸­...'
    });

    console.log(`ðŸ›‘ åœæ­¢å½•éŸ³: ${sessionId}, éŸ³é¢‘å¤§å°: ${session.audioBuffer.length} å­—èŠ‚`);

    // å¤„ç†å½•éŸ³æ•°æ®
    if (session.audioBuffer.length > 0) {
      await this.processRecordedAudio(sessionId);
    } else {
      this.sendError(session.ws, 'å½•éŸ³æ•°æ®ä¸ºç©º');
    }
  }

  /**
   * å¤„ç†éŸ³é¢‘æ•°æ®
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Buffer} audioData - éŸ³é¢‘æ•°æ®
   */
  async handleAudioData(sessionId, audioData) {
    const session = this.activeSessions.get(sessionId);
    if (!session || !session.isRecording) return;

    // ç´¯ç§¯éŸ³é¢‘æ•°æ®
    session.audioBuffer = Buffer.concat([session.audioBuffer, audioData]);

    // å‘é€å½•éŸ³çŠ¶æ€æ›´æ–°
    this.sendMessage(session.ws, {
      type: 'recording_progress',
      audioSize: session.audioBuffer.length,
      duration: Date.now() - session.startTime
    });
  }

  /**
   * å¤„ç†å½•åˆ¶çš„éŸ³é¢‘
   * @param {string} sessionId - ä¼šè¯ID
   */
  async processRecordedAudio(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    try {
      // ç¬¬1æ­¥ï¼šè®¯é£žè¯­éŸ³è¯†åˆ«
      this.sendMessage(session.ws, {
        type: 'processing',
        step: 'transcription',
        message: 'æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...'
      });

      const audioBuffer = this.convertToWav(session.audioBuffer);
      const transcriptionResult = await this.xunfeiService.transcribe(audioBuffer, {
        language: session.language
      });

      if (!transcriptionResult.success) {
        throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥: ' + transcriptionResult.error);
      }

      const transcribedText = transcriptionResult.text;
      console.log(`ðŸ“ è¯†åˆ«ç»“æžœ: "${transcribedText}"`);

      // å‘é€è¯†åˆ«ç»“æžœ
      this.sendMessage(session.ws, {
        type: 'transcription_result',
        data: {
          text: transcribedText,
          confidence: transcriptionResult.confidence,
          language: transcriptionResult.language,
          duration: transcriptionResult.duration
        }
      });

      // ç¬¬2æ­¥ï¼šKimi AIå¤„ç†
      this.sendMessage(session.ws, {
        type: 'processing',
        step: 'ai_response',
        message: 'æ­£åœ¨ç”ŸæˆAIå›žå¤...'
      });

      // æž„å»ºå¯¹è¯åŽ†å²
      const messages = [
        ...session.conversationHistory,
        { role: 'user', content: transcribedText }
      ];

      const chatResult = await this.kimiService.chatWithHistory(messages, session.model);

      if (!chatResult.success) {
        throw new Error('AIå¯¹è¯å¤±è´¥: ' + chatResult.error);
      }

      // æ›´æ–°å¯¹è¯åŽ†å²
      session.conversationHistory = [
        ...messages,
        { role: 'assistant', content: chatResult.data.message }
      ];

      console.log('ðŸ¤– AIå›žå¤ç”Ÿæˆå®Œæˆ');

      // å‘é€æœ€ç»ˆç»“æžœ
      this.sendMessage(session.ws, {
        type: 'complete_result',
        data: {
          transcription: {
            text: transcribedText,
            confidence: transcriptionResult.confidence,
            language: transcriptionResult.language,
            duration: transcriptionResult.duration
          },
          aiResponse: {
            message: chatResult.data.message,
            usage: chatResult.data.usage,
            model: chatResult.data.model
          },
          conversationHistory: session.conversationHistory,
          processingTime: Date.now() - session.startTime
        }
      });

    } catch (error) {
      console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error);
      this.sendError(session.ws, error.message);
    }
  }

  /**
   * è½¬æ¢éŸ³é¢‘ä¸ºWAVæ ¼å¼
   * @param {Buffer} audioBuffer - åŽŸå§‹éŸ³é¢‘æ•°æ®
   * @returns {Buffer} WAVæ ¼å¼éŸ³é¢‘
   */
  convertToWav(audioBuffer) {
    // å¦‚æžœå·²ç»æ˜¯WAVæ ¼å¼ï¼Œç›´æŽ¥è¿”å›ž
    if (audioBuffer.length > 12 && 
        audioBuffer.toString('ascii', 0, 4) === 'RIFF' && 
        audioBuffer.toString('ascii', 8, 12) === 'WAVE') {
      return audioBuffer;
    }

    // ç®€å•çš„WAVå¤´éƒ¨æž„å»ºï¼ˆå‡è®¾16kHz, 16-bit, å•å£°é“ï¼‰
    const sampleRate = 16000;
    const bitsPerSample = 16;
    const channels = 1;
    const byteRate = sampleRate * channels * bitsPerSample / 8;
    const blockAlign = channels * bitsPerSample / 8;
    const dataSize = audioBuffer.length;
    const fileSize = 36 + dataSize;

    const header = Buffer.alloc(44);
    
    // RIFF chunk
    header.write('RIFF', 0);
    header.writeUInt32LE(fileSize, 4);
    header.write('WAVE', 8);
    
    // fmt chunk
    header.write('fmt ', 12);
    header.writeUInt32LE(16, 16);
    header.writeUInt16LE(1, 20);
    header.writeUInt16LE(channels, 22);
    header.writeUInt32LE(sampleRate, 24);
    header.writeUInt32LE(byteRate, 28);
    header.writeUInt16LE(blockAlign, 32);
    header.writeUInt16LE(bitsPerSample, 34);
    
    // data chunk
    header.write('data', 36);
    header.writeUInt32LE(dataSize, 40);

    return Buffer.concat([header, audioBuffer]);
  }

  /**
   * æ›´æ–°é…ç½®
   * @param {string} sessionId - ä¼šè¯ID
   * @param {Object} config - æ–°é…ç½®
   */
  updateConfig(sessionId, config) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    if (config.language) session.language = config.language;
    if (config.model) session.model = config.model;

    this.sendMessage(session.ws, {
      type: 'config_updated',
      config: {
        language: session.language,
        model: session.model
      }
    });
  }

  /**
   * æ¸…é™¤å¯¹è¯åŽ†å²
   * @param {string} sessionId - ä¼šè¯ID
   */
  clearHistory(sessionId) {
    const session = this.activeSessions.get(sessionId);
    if (!session) return;

    session.conversationHistory = [];

    this.sendMessage(session.ws, {
      type: 'history_cleared',
      message: 'å¯¹è¯åŽ†å²å·²æ¸…é™¤'
    });
  }

  /**
   * å‘é€æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
   * @param {WebSocket} ws - WebSocketè¿žæŽ¥
   * @param {Object} message - æ¶ˆæ¯å¯¹è±¡
   */
  sendMessage(ws, message) {
    if (ws.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({
        ...message,
        timestamp: new Date().toISOString()
      }));
    }
  }

  /**
   * å‘é€é”™è¯¯æ¶ˆæ¯
   * @param {WebSocket} ws - WebSocketè¿žæŽ¥
   * @param {string} error - é”™è¯¯ä¿¡æ¯
   */
  sendError(ws, error) {
    this.sendMessage(ws, {
      type: 'error',
      error: error
    });
  }

  /**
   * ç”Ÿæˆä¼šè¯ID
   * @returns {string} ä¼šè¯ID
   */
  generateSessionId() {
    return 'voice_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
  }

  /**
   * èŽ·å–æ´»è·ƒä¼šè¯ç»Ÿè®¡
   * @returns {Object} ç»Ÿè®¡ä¿¡æ¯
   */
  getSessionStats() {
    return {
      activeSessions: this.activeSessions.size,
      sessions: Array.from(this.activeSessions.values()).map(session => ({
        id: session.id,
        isRecording: session.isRecording,
        audioBufferSize: session.audioBuffer.length,
        conversationLength: session.conversationHistory.length,
        uptime: Date.now() - session.startTime
      }))
    };
  }
}

module.exports = RealtimeVoiceService;